{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "nbsphinx": "hidden"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "os.sys.path.insert(0, '/home/schirrmr/braindecode/code/braindecode/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Read and Decode BBCI Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "This tutorial shows how to read and decode BBCI data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Setup logging to see outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "logging.basicConfig(format='%(asctime)s %(levelname)s : %(message)s',\n",
    "                     level=logging.DEBUG, stream=sys.stdout)\n",
    "log = logging.getLogger()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Load and preprocess data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "First set the filename and the sensors you want to load. If you set\n",
    "\n",
    "```python\n",
    "load_sensor_names=None\n",
    "```\n",
    "\n",
    "or just remove the parameter from the function call, all sensors will be loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating RawArray with float64 data, n_channels=3, n_times=3451320\n",
      "    Range : 0 ... 3451319 =      0.000 ...  6902.638 secs\n",
      "Ready.\n"
     ]
    }
   ],
   "source": [
    "from braindecode.datasets.bbci import BBCIDataset\n",
    "train_filename = '/home/schirrmr/data/BBCI-without-last-runs/BhNoMoSc1S001R01_ds10_1-12.BBCI.mat'\n",
    "cnt = BBCIDataset(train_filename, load_sensor_names=['C3', 'CPz', 'C4']).load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Preprocessing on continous data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "First remove the stimulus channel, than apply any preprocessing you like. There are some very few directions available from Braindecode, such as resample_cnt. But you can apply any function on the chan x time matrix of the mne raw object (`cnt` in the code) by calling `mne_apply` with two arguments:\n",
    "\n",
    "1. Your function (2d-array-> 2darray), that transforms the channel x timesteps data array\n",
    "2. the Raw data object from mne itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-07-05 13:08:15,051 WARNING : This is not causal, uses future data....\n",
      "2017-07-05 13:08:15,055 INFO : Resampling from 500.000000 to 250.000000 Hz.\n",
      "Creating RawArray with float64 data, n_channels=3, n_times=1725660\n",
      "    Range : 0 ... 1725659 =      0.000 ...  6902.636 secs\n",
      "Ready.\n"
     ]
    }
   ],
   "source": [
    "from braindecode.mne_ext.signalproc import resample_cnt, mne_apply\n",
    "from braindecode.datautil.signalproc import exponential_running_standardize\n",
    "# Remove stimulus channel\n",
    "cnt = cnt.drop_channels(['STI 014'])\n",
    "cnt = resample_cnt(cnt, 250)\n",
    "# mne apply will apply the function to the data (a 2d-numpy-array)\n",
    "# have to transpose data back and forth, since\n",
    "# exponential_running_standardize expects time x chans order\n",
    "# while mne object has chans x time order\n",
    "cnt = mne_apply(lambda a: exponential_running_standardize(\n",
    "    a.T, init_block_size=1000,factor_new=0.001, eps=1e-4).T,\n",
    "    cnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Transform to epoched dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Braindecode supplies the `create_signal_target_from_raw_mne` function, which will transform the mne raw object into a `SignalAndTarget` object for use in Braindecode.\n",
    "`name_to_code` should be an `OrderedDict` that maps class names to either one or a list of marker codes for that class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-07-05 13:08:18,890 INFO : Trial per class:\n",
      "Counter({'Feet': 225, 'Rest': 224, 'Left': 224, 'Right': 224})\n"
     ]
    }
   ],
   "source": [
    "from braindecode.datautil.trial_segment import create_signal_target_from_raw_mne\n",
    "from collections import OrderedDict\n",
    "# can also give lists of marker codes in case a class has multiple marker codes...\n",
    "name_to_code = OrderedDict([('Right', 1), ('Left', 2), ('Rest', 3), ('Feet', 4)])\n",
    "segment_ival_ms = [-500,4000]\n",
    "\n",
    "train_set = create_signal_target_from_raw_mne(cnt, name_to_code, segment_ival_ms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Same for test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating RawArray with float64 data, n_channels=3, n_times=617090\n",
      "    Range : 0 ... 617089 =      0.000 ...  1234.178 secs\n",
      "Ready.\n",
      "2017-07-05 13:08:19,285 WARNING : This is not causal, uses future data....\n",
      "2017-07-05 13:08:19,287 INFO : Resampling from 500.000000 to 250.000000 Hz.\n",
      "Creating RawArray with float64 data, n_channels=3, n_times=308545\n",
      "    Range : 0 ... 308544 =      0.000 ...  1234.176 secs\n",
      "Ready.\n",
      "2017-07-05 13:08:19,662 INFO : Trial per class:\n",
      "Counter({'Rest': 40, 'Left': 40, 'Right': 40, 'Feet': 40})\n"
     ]
    }
   ],
   "source": [
    "test_filename = '/home/schirrmr/data/BBCI-only-last-runs/BhNoMoSc1S001R13_ds10_1-2BBCI.mat'\n",
    "cnt = BBCIDataset(test_filename, load_sensor_names=['C3', 'CPz', 'C4']).load()\n",
    "# Remove stimulus channel\n",
    "cnt = cnt.drop_channels(['STI 014'])\n",
    "cnt = resample_cnt(cnt, 250)\n",
    "cnt = mne_apply(lambda a: exponential_running_standardize(\n",
    "    a.T, init_block_size=1000,factor_new=0.001, eps=1e-4).T,\n",
    "    cnt)\n",
    "test_set = create_signal_target_from_raw_mne(cnt, name_to_code, segment_ival_ms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "In case of start and stop markers, provide a `name_to_stop_codes` dictionary (same as for the start codes in this example) as a final argument to `create_signal_target_from_raw_mne`. See [Read and Decode BBCI Data with Start-Stop-Markers Tutorial](BBCI_Data_Start_Stop.html)\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Split off a validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from braindecode.datautil.splitters import split_into_two_sets\n",
    "\n",
    "train_set, valid_set = split_into_two_sets(train_set, first_set_fraction=0.8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from braindecode.models.shallow_fbcsp import ShallowFBCSPNet\n",
    "from torch import nn\n",
    "from braindecode.torch_ext.util import set_random_seeds\n",
    "from braindecode.models.util import to_dense_prediction_model\n",
    "\n",
    "# Set if you want to use GPU\n",
    "# You can also use torch.cuda.is_available() to determine if cuda is available on your machine.\n",
    "cuda = True\n",
    "set_random_seeds(seed=20170629, cuda=cuda)\n",
    "\n",
    "# This will determine how many crops are processed in parallel\n",
    "input_time_length = 800\n",
    "in_chans = 3\n",
    "n_classes = 4\n",
    "# final_conv_length determines the size of the receptive field of the ConvNet\n",
    "model = ShallowFBCSPNet(in_chans=in_chans, n_classes=n_classes, input_time_length=input_time_length,\n",
    "                        final_conv_length=30).create_network()\n",
    "to_dense_prediction_model(model)\n",
    "\n",
    "if cuda:\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Setup optimizer and iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "267 predictions per input/trial\n"
     ]
    }
   ],
   "source": [
    "from torch import optim\n",
    "import numpy as np\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "from braindecode.torch_ext.util import np_to_var\n",
    "# determine output size\n",
    "test_input = np_to_var(np.ones((2, 3, input_time_length, 1), dtype=np.float32))\n",
    "if cuda:\n",
    "    test_input = test_input.cuda()\n",
    "out = model(test_input)\n",
    "n_preds_per_input = out.cpu().data.numpy().shape[2]\n",
    "print(\"{:d} predictions per input/trial\".format(n_preds_per_input))\n",
    "\n",
    "from braindecode.datautil.iterators import CropsFromTrialsIterator\n",
    "iterator = CropsFromTrialsIterator(batch_size=32,input_time_length=input_time_length,\n",
    "                                  n_preds_per_input=n_preds_per_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Setup Monitors, Loss function, Stop Criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from braindecode.experiments.experiment import Experiment\n",
    "from braindecode.experiments.monitors import RuntimeMonitor, LossMonitor, CroppedTrialMisclassMonitor, MisclassMonitor\n",
    "from braindecode.experiments.stopcriteria import MaxEpochs\n",
    "import torch.nn.functional as F\n",
    "import torch as th\n",
    "from braindecode.torch_ext.modules import Expression\n",
    "\n",
    "\n",
    "loss_function = lambda preds, targets: F.nll_loss(th.mean(preds, dim=2)[:,:,0], targets)\n",
    "\n",
    "model_constraint = None\n",
    "monitors = [LossMonitor(), MisclassMonitor(col_suffix='sample_misclass'),\n",
    "            CroppedTrialMisclassMonitor(input_time_length), RuntimeMonitor(),]\n",
    "stop_criterion = MaxEpochs(20)\n",
    "exp = Experiment(model, train_set, valid_set, test_set, iterator, loss_function, optimizer, model_constraint,\n",
    "          monitors, stop_criterion, remember_best_column='valid_misclass',\n",
    "          run_after_early_stop=True, batch_modifier=None, cuda=cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Run experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-07-05 13:08:26,137 INFO : Run until first stop...\n",
      "2017-07-05 13:08:26,768 INFO : Epoch 0\n",
      "2017-07-05 13:08:26,771 INFO : train_loss                7.89184\n",
      "2017-07-05 13:08:26,772 INFO : valid_loss                7.72731\n",
      "2017-07-05 13:08:26,774 INFO : test_loss                 7.75617\n",
      "2017-07-05 13:08:26,775 INFO : train_sample_misclass     0.75013\n",
      "2017-07-05 13:08:26,777 INFO : valid_sample_misclass     0.74856\n",
      "2017-07-05 13:08:26,778 INFO : test_sample_misclass      0.75115\n",
      "2017-07-05 13:08:26,779 INFO : train_misclass            0.75070\n",
      "2017-07-05 13:08:26,781 INFO : valid_misclass            0.74860\n",
      "2017-07-05 13:08:26,782 INFO : test_misclass             0.75000\n",
      "2017-07-05 13:08:26,784 INFO : runtime                   0.00000\n",
      "2017-07-05 13:08:26,785 INFO : \n",
      "2017-07-05 13:08:26,787 INFO : New best valid_misclass: 0.748603\n",
      "2017-07-05 13:08:26,789 INFO : \n",
      "2017-07-05 13:08:28,397 INFO : Epoch 1\n",
      "2017-07-05 13:08:28,399 INFO : train_loss                0.79556\n",
      "2017-07-05 13:08:28,400 INFO : valid_loss                0.79311\n",
      "2017-07-05 13:08:28,402 INFO : test_loss                 0.83740\n",
      "2017-07-05 13:08:28,403 INFO : train_sample_misclass     0.36954\n",
      "2017-07-05 13:08:28,405 INFO : valid_sample_misclass     0.37415\n",
      "2017-07-05 13:08:28,407 INFO : test_sample_misclass      0.43035\n",
      "2017-07-05 13:08:28,408 INFO : train_misclass            0.30223\n",
      "2017-07-05 13:08:28,410 INFO : valid_misclass            0.26257\n",
      "2017-07-05 13:08:28,411 INFO : test_misclass             0.34375\n",
      "2017-07-05 13:08:28,413 INFO : runtime                   1.50600\n",
      "2017-07-05 13:08:28,414 INFO : \n",
      "2017-07-05 13:08:28,417 INFO : New best valid_misclass: 0.262570\n",
      "2017-07-05 13:08:28,418 INFO : \n",
      "2017-07-05 13:08:29,833 INFO : Epoch 2\n",
      "2017-07-05 13:08:29,836 INFO : train_loss                0.68086\n",
      "2017-07-05 13:08:29,837 INFO : valid_loss                0.65868\n",
      "2017-07-05 13:08:29,839 INFO : test_loss                 0.74243\n",
      "2017-07-05 13:08:29,840 INFO : train_sample_misclass     0.29305\n",
      "2017-07-05 13:08:29,842 INFO : valid_sample_misclass     0.30217\n",
      "2017-07-05 13:08:29,844 INFO : test_sample_misclass      0.37369\n",
      "2017-07-05 13:08:29,845 INFO : train_misclass            0.22563\n",
      "2017-07-05 13:08:29,847 INFO : valid_misclass            0.21229\n",
      "2017-07-05 13:08:29,848 INFO : test_misclass             0.29375\n",
      "2017-07-05 13:08:29,850 INFO : runtime                   1.58078\n",
      "2017-07-05 13:08:29,852 INFO : \n",
      "2017-07-05 13:08:29,855 INFO : New best valid_misclass: 0.212291\n",
      "2017-07-05 13:08:29,857 INFO : \n",
      "2017-07-05 13:08:31,607 INFO : Epoch 3\n",
      "2017-07-05 13:08:31,610 INFO : train_loss                0.65421\n",
      "2017-07-05 13:08:31,611 INFO : valid_loss                0.68348\n",
      "2017-07-05 13:08:31,613 INFO : test_loss                 0.81472\n",
      "2017-07-05 13:08:31,614 INFO : train_sample_misclass     0.27840\n",
      "2017-07-05 13:08:31,616 INFO : valid_sample_misclass     0.32118\n",
      "2017-07-05 13:08:31,617 INFO : test_sample_misclass      0.43559\n",
      "2017-07-05 13:08:31,619 INFO : train_misclass            0.20334\n",
      "2017-07-05 13:08:31,620 INFO : valid_misclass            0.26257\n",
      "2017-07-05 13:08:31,622 INFO : test_misclass             0.35625\n",
      "2017-07-05 13:08:31,623 INFO : runtime                   1.58373\n",
      "2017-07-05 13:08:31,625 INFO : \n",
      "2017-07-05 13:08:32,946 INFO : Epoch 4\n",
      "2017-07-05 13:08:32,949 INFO : train_loss                0.58900\n",
      "2017-07-05 13:08:32,950 INFO : valid_loss                0.58785\n",
      "2017-07-05 13:08:32,952 INFO : test_loss                 0.72343\n",
      "2017-07-05 13:08:32,953 INFO : train_sample_misclass     0.25888\n",
      "2017-07-05 13:08:32,955 INFO : valid_sample_misclass     0.25596\n",
      "2017-07-05 13:08:32,956 INFO : test_sample_misclass      0.35243\n",
      "2017-07-05 13:08:32,958 INFO : train_misclass            0.20891\n",
      "2017-07-05 13:08:32,959 INFO : valid_misclass            0.18994\n",
      "2017-07-05 13:08:32,961 INFO : test_misclass             0.30000\n",
      "2017-07-05 13:08:32,962 INFO : runtime                   1.54172\n",
      "2017-07-05 13:08:32,964 INFO : \n",
      "2017-07-05 13:08:32,966 INFO : New best valid_misclass: 0.189944\n",
      "2017-07-05 13:08:32,968 INFO : \n",
      "2017-07-05 13:08:34,293 INFO : Epoch 5\n",
      "2017-07-05 13:08:34,294 INFO : train_loss                0.63505\n",
      "2017-07-05 13:08:34,295 INFO : valid_loss                0.58610\n",
      "2017-07-05 13:08:34,296 INFO : test_loss                 0.66994\n",
      "2017-07-05 13:08:34,297 INFO : train_sample_misclass     0.24059\n",
      "2017-07-05 13:08:34,297 INFO : valid_sample_misclass     0.27062\n",
      "2017-07-05 13:08:34,298 INFO : test_sample_misclass      0.31571\n",
      "2017-07-05 13:08:34,299 INFO : train_misclass            0.17549\n",
      "2017-07-05 13:08:34,300 INFO : valid_misclass            0.18994\n",
      "2017-07-05 13:08:34,300 INFO : test_misclass             0.24375\n",
      "2017-07-05 13:08:34,301 INFO : runtime                   1.34251\n",
      "2017-07-05 13:08:34,302 INFO : \n",
      "2017-07-05 13:08:34,303 INFO : New best valid_misclass: 0.189944\n",
      "2017-07-05 13:08:34,304 INFO : \n",
      "2017-07-05 13:08:35,733 INFO : Epoch 6\n",
      "2017-07-05 13:08:35,735 INFO : train_loss                0.63143\n",
      "2017-07-05 13:08:35,737 INFO : valid_loss                0.67554\n",
      "2017-07-05 13:08:35,738 INFO : test_loss                 0.75946\n",
      "2017-07-05 13:08:35,740 INFO : train_sample_misclass     0.28382\n",
      "2017-07-05 13:08:35,741 INFO : valid_sample_misclass     0.29700\n",
      "2017-07-05 13:08:35,743 INFO : test_sample_misclass      0.36886\n",
      "2017-07-05 13:08:35,744 INFO : train_misclass            0.21866\n",
      "2017-07-05 13:08:35,746 INFO : valid_misclass            0.24581\n",
      "2017-07-05 13:08:35,747 INFO : test_misclass             0.33750\n",
      "2017-07-05 13:08:35,749 INFO : runtime                   1.34113\n",
      "2017-07-05 13:08:35,750 INFO : \n",
      "2017-07-05 13:08:37,662 INFO : Epoch 7\n",
      "2017-07-05 13:08:37,664 INFO : train_loss                0.57133\n",
      "2017-07-05 13:08:37,664 INFO : valid_loss                0.54882\n",
      "2017-07-05 13:08:37,665 INFO : test_loss                 0.64240\n",
      "2017-07-05 13:08:37,666 INFO : train_sample_misclass     0.22843\n",
      "2017-07-05 13:08:37,667 INFO : valid_sample_misclass     0.24762\n",
      "2017-07-05 13:08:37,668 INFO : test_sample_misclass      0.29690\n",
      "2017-07-05 13:08:37,668 INFO : train_misclass            0.17827\n",
      "2017-07-05 13:08:37,669 INFO : valid_misclass            0.17318\n",
      "2017-07-05 13:08:37,670 INFO : test_misclass             0.23750\n",
      "2017-07-05 13:08:37,671 INFO : runtime                   1.58787\n",
      "2017-07-05 13:08:37,671 INFO : \n",
      "2017-07-05 13:08:37,673 INFO : New best valid_misclass: 0.173184\n",
      "2017-07-05 13:08:37,674 INFO : \n",
      "2017-07-05 13:08:39,101 INFO : Epoch 8\n",
      "2017-07-05 13:08:39,103 INFO : train_loss                0.52402\n",
      "2017-07-05 13:08:39,105 INFO : valid_loss                0.59956\n",
      "2017-07-05 13:08:39,107 INFO : test_loss                 0.74478\n",
      "2017-07-05 13:08:39,108 INFO : train_sample_misclass     0.23295\n",
      "2017-07-05 13:08:39,110 INFO : valid_sample_misclass     0.26964\n",
      "2017-07-05 13:08:39,111 INFO : test_sample_misclass      0.37200\n",
      "2017-07-05 13:08:39,113 INFO : train_misclass            0.16852\n",
      "2017-07-05 13:08:39,114 INFO : valid_misclass            0.17877\n",
      "2017-07-05 13:08:39,116 INFO : test_misclass             0.30625\n",
      "2017-07-05 13:08:39,117 INFO : runtime                   1.87614\n",
      "2017-07-05 13:08:39,119 INFO : \n",
      "2017-07-05 13:08:40,525 INFO : Epoch 9\n",
      "2017-07-05 13:08:40,527 INFO : train_loss                0.55360\n",
      "2017-07-05 13:08:40,529 INFO : valid_loss                0.56227\n",
      "2017-07-05 13:08:40,530 INFO : test_loss                 0.69762\n",
      "2017-07-05 13:08:40,532 INFO : train_sample_misclass     0.23241\n",
      "2017-07-05 13:08:40,533 INFO : valid_sample_misclass     0.25905\n",
      "2017-07-05 13:08:40,535 INFO : test_sample_misclass      0.34351\n",
      "2017-07-05 13:08:40,536 INFO : train_misclass            0.19220\n",
      "2017-07-05 13:08:40,538 INFO : valid_misclass            0.16760\n",
      "2017-07-05 13:08:40,539 INFO : test_misclass             0.25625\n",
      "2017-07-05 13:08:40,541 INFO : runtime                   1.42494\n",
      "2017-07-05 13:08:40,542 INFO : \n",
      "2017-07-05 13:08:40,545 INFO : New best valid_misclass: 0.167598\n",
      "2017-07-05 13:08:40,546 INFO : \n",
      "2017-07-05 13:08:42,564 INFO : Epoch 10\n",
      "2017-07-05 13:08:42,581 INFO : train_loss                0.49796\n",
      "2017-07-05 13:08:42,583 INFO : valid_loss                0.51592\n",
      "2017-07-05 13:08:42,585 INFO : test_loss                 0.61930\n",
      "2017-07-05 13:08:42,587 INFO : train_sample_misclass     0.20153\n",
      "2017-07-05 13:08:42,601 INFO : valid_sample_misclass     0.24240\n",
      "2017-07-05 13:08:42,603 INFO : test_sample_misclass      0.29188\n",
      "2017-07-05 13:08:42,605 INFO : train_misclass            0.13231\n",
      "2017-07-05 13:08:42,606 INFO : valid_misclass            0.16201\n",
      "2017-07-05 13:08:42,608 INFO : test_misclass             0.20625\n",
      "2017-07-05 13:08:42,609 INFO : runtime                   1.49812\n",
      "2017-07-05 13:08:42,611 INFO : \n",
      "2017-07-05 13:08:42,613 INFO : New best valid_misclass: 0.162011\n",
      "2017-07-05 13:08:42,615 INFO : \n",
      "2017-07-05 13:08:44,613 INFO : Epoch 11\n",
      "2017-07-05 13:08:44,615 INFO : train_loss                0.49093\n",
      "2017-07-05 13:08:44,616 INFO : valid_loss                0.56000\n",
      "2017-07-05 13:08:44,618 INFO : test_loss                 0.63385\n",
      "2017-07-05 13:08:44,620 INFO : train_sample_misclass     0.20331\n",
      "2017-07-05 13:08:44,621 INFO : valid_sample_misclass     0.25930\n",
      "2017-07-05 13:08:44,623 INFO : test_sample_misclass      0.31032\n",
      "2017-07-05 13:08:44,624 INFO : train_misclass            0.12813\n",
      "2017-07-05 13:08:44,626 INFO : valid_misclass            0.20112\n",
      "2017-07-05 13:08:44,627 INFO : test_misclass             0.23125\n",
      "2017-07-05 13:08:44,629 INFO : runtime                   2.41092\n",
      "2017-07-05 13:08:44,631 INFO : \n",
      "2017-07-05 13:08:46,348 INFO : Epoch 12\n",
      "2017-07-05 13:08:46,351 INFO : train_loss                0.52692\n",
      "2017-07-05 13:08:46,352 INFO : valid_loss                0.58040\n",
      "2017-07-05 13:08:46,354 INFO : test_loss                 0.67022\n",
      "2017-07-05 13:08:46,355 INFO : train_sample_misclass     0.22043\n",
      "2017-07-05 13:08:46,357 INFO : valid_sample_misclass     0.26338\n",
      "2017-07-05 13:08:46,358 INFO : test_sample_misclass      0.31268\n",
      "2017-07-05 13:08:46,360 INFO : train_misclass            0.15042\n",
      "2017-07-05 13:08:46,361 INFO : valid_misclass            0.21788\n",
      "2017-07-05 13:08:46,363 INFO : test_misclass             0.23750\n",
      "2017-07-05 13:08:46,364 INFO : runtime                   1.74436\n",
      "2017-07-05 13:08:46,366 INFO : \n",
      "2017-07-05 13:08:47,698 INFO : Epoch 13\n",
      "2017-07-05 13:08:47,700 INFO : train_loss                0.52302\n",
      "2017-07-05 13:08:47,702 INFO : valid_loss                0.57684\n",
      "2017-07-05 13:08:47,703 INFO : test_loss                 0.76789\n",
      "2017-07-05 13:08:47,705 INFO : train_sample_misclass     0.21812\n",
      "2017-07-05 13:08:47,706 INFO : valid_sample_misclass     0.25921\n",
      "2017-07-05 13:08:47,708 INFO : test_sample_misclass      0.37843\n",
      "2017-07-05 13:08:47,709 INFO : train_misclass            0.15181\n",
      "2017-07-05 13:08:47,711 INFO : valid_misclass            0.17318\n",
      "2017-07-05 13:08:47,712 INFO : test_misclass             0.28750\n",
      "2017-07-05 13:08:47,714 INFO : runtime                   1.52670\n",
      "2017-07-05 13:08:47,715 INFO : \n",
      "2017-07-05 13:08:49,047 INFO : Epoch 14\n",
      "2017-07-05 13:08:49,049 INFO : train_loss                0.51160\n",
      "2017-07-05 13:08:49,051 INFO : valid_loss                0.48732\n",
      "2017-07-05 13:08:49,052 INFO : test_loss                 0.62945\n",
      "2017-07-05 13:08:49,054 INFO : train_sample_misclass     0.19050\n",
      "2017-07-05 13:08:49,055 INFO : valid_sample_misclass     0.21891\n",
      "2017-07-05 13:08:49,057 INFO : test_sample_misclass      0.30675\n",
      "2017-07-05 13:08:49,058 INFO : train_misclass            0.12256\n",
      "2017-07-05 13:08:49,060 INFO : valid_misclass            0.15084\n",
      "2017-07-05 13:08:49,061 INFO : test_misclass             0.23125\n",
      "2017-07-05 13:08:49,063 INFO : runtime                   1.34275\n",
      "2017-07-05 13:08:49,064 INFO : \n",
      "2017-07-05 13:08:49,067 INFO : New best valid_misclass: 0.150838\n",
      "2017-07-05 13:08:49,068 INFO : \n",
      "2017-07-05 13:08:50,399 INFO : Epoch 15\n",
      "2017-07-05 13:08:50,401 INFO : train_loss                0.53429\n",
      "2017-07-05 13:08:50,403 INFO : valid_loss                0.53380\n",
      "2017-07-05 13:08:50,404 INFO : test_loss                 0.65969\n",
      "2017-07-05 13:08:50,406 INFO : train_sample_misclass     0.21640\n",
      "2017-07-05 13:08:50,407 INFO : valid_sample_misclass     0.23704\n",
      "2017-07-05 13:08:50,409 INFO : test_sample_misclass      0.31877\n",
      "2017-07-05 13:08:50,410 INFO : train_misclass            0.16156\n",
      "2017-07-05 13:08:50,412 INFO : valid_misclass            0.16760\n",
      "2017-07-05 13:08:50,413 INFO : test_misclass             0.25000\n",
      "2017-07-05 13:08:50,415 INFO : runtime                   1.35698\n",
      "2017-07-05 13:08:50,416 INFO : \n",
      "2017-07-05 13:08:51,907 INFO : Epoch 16\n",
      "2017-07-05 13:08:51,909 INFO : train_loss                0.53959\n",
      "2017-07-05 13:08:51,911 INFO : valid_loss                0.59163\n",
      "2017-07-05 13:08:51,913 INFO : test_loss                 0.71524\n",
      "2017-07-05 13:08:51,914 INFO : train_sample_misclass     0.21590\n",
      "2017-07-05 13:08:51,916 INFO : valid_sample_misclass     0.25921\n",
      "2017-07-05 13:08:51,917 INFO : test_sample_misclass      0.34952\n",
      "2017-07-05 13:08:51,919 INFO : train_misclass            0.16156\n",
      "2017-07-05 13:08:51,920 INFO : valid_misclass            0.20112\n",
      "2017-07-05 13:08:51,922 INFO : test_misclass             0.27500\n",
      "2017-07-05 13:08:51,923 INFO : runtime                   1.46076\n",
      "2017-07-05 13:08:51,925 INFO : \n",
      "2017-07-05 13:08:53,557 INFO : Epoch 17\n",
      "2017-07-05 13:08:53,559 INFO : train_loss                0.50836\n",
      "2017-07-05 13:08:53,562 INFO : valid_loss                0.56502\n",
      "2017-07-05 13:08:53,564 INFO : test_loss                 0.66951\n",
      "2017-07-05 13:08:53,566 INFO : train_sample_misclass     0.21432\n",
      "2017-07-05 13:08:53,568 INFO : valid_sample_misclass     0.24485\n",
      "2017-07-05 13:08:53,569 INFO : test_sample_misclass      0.33031\n",
      "2017-07-05 13:08:53,571 INFO : train_misclass            0.16295\n",
      "2017-07-05 13:08:53,572 INFO : valid_misclass            0.18436\n",
      "2017-07-05 13:08:53,574 INFO : test_misclass             0.26875\n",
      "2017-07-05 13:08:53,575 INFO : runtime                   1.44252\n",
      "2017-07-05 13:08:53,577 INFO : \n",
      "2017-07-05 13:08:55,304 INFO : Epoch 18\n",
      "2017-07-05 13:08:55,306 INFO : train_loss                0.47487\n",
      "2017-07-05 13:08:55,308 INFO : valid_loss                0.52509\n",
      "2017-07-05 13:08:55,309 INFO : test_loss                 0.65588\n",
      "2017-07-05 13:08:55,310 INFO : train_sample_misclass     0.19093\n",
      "2017-07-05 13:08:55,311 INFO : valid_sample_misclass     0.23959\n",
      "2017-07-05 13:08:55,312 INFO : test_sample_misclass      0.32414\n",
      "2017-07-05 13:08:55,313 INFO : train_misclass            0.11699\n",
      "2017-07-05 13:08:55,314 INFO : valid_misclass            0.16760\n",
      "2017-07-05 13:08:55,315 INFO : test_misclass             0.23125\n",
      "2017-07-05 13:08:55,316 INFO : runtime                   1.85329\n",
      "2017-07-05 13:08:55,317 INFO : \n",
      "2017-07-05 13:08:56,837 INFO : Epoch 19\n",
      "2017-07-05 13:08:56,838 INFO : train_loss                0.54682\n",
      "2017-07-05 13:08:56,839 INFO : valid_loss                0.55416\n",
      "2017-07-05 13:08:56,840 INFO : test_loss                 0.70849\n",
      "2017-07-05 13:08:56,840 INFO : train_sample_misclass     0.21729\n",
      "2017-07-05 13:08:56,841 INFO : valid_sample_misclass     0.25268\n",
      "2017-07-05 13:08:56,841 INFO : test_sample_misclass      0.34338\n",
      "2017-07-05 13:08:56,842 INFO : train_misclass            0.17131\n",
      "2017-07-05 13:08:56,843 INFO : valid_misclass            0.17318\n",
      "2017-07-05 13:08:56,843 INFO : test_misclass             0.26250\n",
      "2017-07-05 13:08:56,844 INFO : runtime                   1.66664\n",
      "2017-07-05 13:08:56,844 INFO : \n",
      "2017-07-05 13:08:58,193 INFO : Epoch 20\n",
      "2017-07-05 13:08:58,194 INFO : train_loss                0.46215\n",
      "2017-07-05 13:08:58,195 INFO : valid_loss                0.52436\n",
      "2017-07-05 13:08:58,195 INFO : test_loss                 0.61303\n",
      "2017-07-05 13:08:58,196 INFO : train_sample_misclass     0.18500\n",
      "2017-07-05 13:08:58,197 INFO : valid_sample_misclass     0.23195\n",
      "2017-07-05 13:08:58,197 INFO : test_sample_misclass      0.28649\n",
      "2017-07-05 13:08:58,198 INFO : train_misclass            0.10724\n",
      "2017-07-05 13:08:58,199 INFO : valid_misclass            0.16201\n",
      "2017-07-05 13:08:58,199 INFO : test_misclass             0.23750\n",
      "2017-07-05 13:08:58,200 INFO : runtime                   1.35679\n",
      "2017-07-05 13:08:58,201 INFO : \n",
      "2017-07-05 13:08:58,202 INFO : Setup for second stop...\n",
      "2017-07-05 13:08:58,204 INFO : Train loss to reach 0.51160\n",
      "2017-07-05 13:08:58,205 INFO : Run until second stop...\n",
      "2017-07-05 13:08:58,938 INFO : Epoch 15\n",
      "2017-07-05 13:08:58,939 INFO : train_loss                0.50676\n",
      "2017-07-05 13:08:58,940 INFO : valid_loss                0.48732\n",
      "2017-07-05 13:08:58,940 INFO : test_loss                 0.62945\n",
      "2017-07-05 13:08:58,941 INFO : train_sample_misclass     0.19617\n",
      "2017-07-05 13:08:58,941 INFO : valid_sample_misclass     0.21891\n",
      "2017-07-05 13:08:58,942 INFO : test_sample_misclass      0.30675\n",
      "2017-07-05 13:08:58,943 INFO : train_misclass            0.12821\n",
      "2017-07-05 13:08:58,943 INFO : valid_misclass            0.15084\n",
      "2017-07-05 13:08:58,944 INFO : test_misclass             0.23125\n",
      "2017-07-05 13:08:58,945 INFO : runtime                   0.62562\n",
      "2017-07-05 13:08:58,945 INFO : \n"
     ]
    }
   ],
   "source": [
    "exp.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We arrive at ca. 77% accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "If you want to do trialwise decoding instead of cropped decoding, perform the following changes:\n",
    "\n",
    "\n",
    "Change:\n",
    "```python\n",
    "# This will determine how many crops are processed in parallel\n",
    "input_time_length = 800\n",
    "in_chans = 3\n",
    "n_classes = 4\n",
    "# final_conv_length determines the size of the receptive field of the ConvNet\n",
    "model = ShallowFBCSPNet(in_chans=in_chans, n_classes=n_classes, input_time_length=input_time_length,\n",
    "                        final_conv_length=30).create_network()\n",
    "```\n",
    "\n",
    "to:\n",
    "```python\n",
    "# This will determine how many crops are processed in parallel\n",
    "input_time_length = train_set.X.shape[2]\n",
    "in_chans = 3\n",
    "n_classes = 4\n",
    "# final_conv_length determines the size of the receptive field of the ConvNet\n",
    "model = ShallowFBCSPNet(in_chans=in_chans, n_classes=n_classes, input_time_length=input_time_length,\n",
    "                        final_conv_length='auto').create_network()\n",
    "```\n",
    "\n",
    "Remove:\n",
    "\n",
    "```python\n",
    "to_dense_prediction_model(model)\n",
    "```\n",
    "\n",
    "Remove:\n",
    "\n",
    "\n",
    "```python\n",
    "from braindecode.torch_ext.util import np_to_var\n",
    "# determine output size\n",
    "test_input = np_to_var(np.ones((2, 3, input_time_length, 1), dtype=np.float32))\n",
    "if cuda:\n",
    "    test_input = test_input.cuda()\n",
    "out = model(test_input)\n",
    "n_preds_per_input = out.cpu().data.numpy().shape[2]\n",
    "print(\"{:d} predictions per input/trial\".format(n_preds_per_input))\n",
    "```\n",
    "\n",
    "Change:\n",
    "\n",
    "```python\n",
    "from braindecode.datautil.iterators import CropsFromTrialsIterator\n",
    "iterator = CropsFromTrialsIterator(batch_size=32,input_time_length=input_time_length,\n",
    "                                  n_preds_per_input=n_preds_per_input)\n",
    "```\n",
    "\n",
    "to:\n",
    "\n",
    "```python\n",
    "from braindecode.datautil.iterators import BalancedBatchSizeIterator\n",
    "iterator = BalancedBatchSizeIterator(batch_size=32)\n",
    "```\n",
    "\n",
    "\n",
    "Change:\n",
    "\n",
    "```python\n",
    "loss_function = lambda preds, targets: F.nll_loss(th.mean(preds, dim=2)[:,:,0], targets)\n",
    "```\n",
    "\n",
    "to:\n",
    "\n",
    "```python\n",
    "loss_function = F.nll_loss\n",
    "```\n",
    "\n",
    "Change:\n",
    "\n",
    "```python\n",
    "monitors = [LossMonitor(), MisclassMonitor(col_suffix='sample_misclass'),\n",
    "            CroppedTrialMisclassMonitor(input_time_length), RuntimeMonitor(),]\n",
    "```\n",
    "\n",
    "to:\n",
    "\n",
    "```python\n",
    "monitors = [LossMonitor(), MisclassMonitor(col_suffix='misclass'), \n",
    "            RuntimeMonitor(),]\n",
    "```\n",
    "\n",
    "Resulting code can be seen at [BBCI Data Epoched](BBCI_Data_Epoched.html)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
