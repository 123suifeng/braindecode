{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "nbsphinx": "hidden"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "os.sys.path.insert(0, '/home/schirrmr/braindecode/code/braindecode/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Using the Experiment Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Braindecode provides a convenience `Experiment` class, which removes the necessity to write your own training loop. It expects a training, a validation and a test set and trains as follows:\n",
    "\n",
    "1. Train on training set until a given stop criterion is fulfilled\n",
    "2. Reset to the best epoch, i.e. reset parameters of the model and the optimizer to the state at the best epoch (\"best\" according to a given criterion) \n",
    "3. Continue training on the combined training + validation set until the loss on the validation set is as low as it was on the best epoch for the training set. (or until the ConvNet was trained twice as many epochs as the best epoch to prevent infinite training)\n",
    "\n",
    "<div class='alert alert-warning'>\n",
    "\n",
    "It is not necessary to use the Experiment class to use the remaning functionality of Braindecode. Feel free to ignore it :)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing orphaned offset at the beginning of the file.\n",
      "179 events found\n",
      "Events id: [1 2 3]\n",
      "90 matching events found\n",
      "Loading data for 90 events and 497 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    }
   ],
   "source": [
    "import mne\n",
    "from mne.io import concatenate_raws\n",
    "\n",
    "# 5,6,7,10,13,14 are codes for executed and imagined hands/feet\n",
    "subject_id = 1\n",
    "event_codes = [5,6,9,10,13,14]\n",
    "\n",
    "# This will download the files if you don't have them yet,\n",
    "# and then return the paths to the files.\n",
    "physionet_paths = mne.datasets.eegbci.load_data(subject_id, event_codes)\n",
    "\n",
    "# Load each of the files\n",
    "parts = [mne.io.read_raw_edf(path, preload=True,stim_channel='auto', verbose='WARNING')\n",
    "         for path in physionet_paths]\n",
    "\n",
    "# Concatenate them\n",
    "raw = concatenate_raws(parts)\n",
    "\n",
    "# Find the events in this dataset\n",
    "events = mne.find_events(raw, shortest_event=0, stim_channel='STI 014')\n",
    "\n",
    "# Use only EEG channels\n",
    "eeg_channel_inds = mne.pick_types(raw.info, meg=False, eeg=True, stim=False, eog=False,\n",
    "                   exclude='bads')\n",
    "\n",
    "# Extract trials, only using EEG channels\n",
    "epoched = mne.Epochs(raw, events, dict(hands=2, feet=3), tmin=1, tmax=4.1, proj=False, picks=eeg_channel_inds,\n",
    "                baseline=None, preload=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Convert data to Braindecode Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from braindecode.datautil.signal_target import SignalAndTarget\n",
    "from braindecode.datautil.splitters import split_into_two_sets\n",
    "# Convert data from volt to millivolt\n",
    "# Pytorch expects float32 for input and int64 for labels.\n",
    "X = (epoched.get_data() * 1e6).astype(np.float32)\n",
    "y = (epoched.events[:,2] - 2).astype(np.int64) #2,3 -> 0,1\n",
    "\n",
    "train_set = SignalAndTarget(X[:60], y=y[:60])\n",
    "test_set = SignalAndTarget(X[60:], y=y[60:])\n",
    "\n",
    "train_set, valid_set = split_into_two_sets(train_set, first_set_fraction=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from braindecode.models.shallow_fbcsp import ShallowFBCSPNet\n",
    "from torch import nn\n",
    "from braindecode.torch_ext.util import set_random_seeds\n",
    "from braindecode.models.util import to_dense_prediction_model\n",
    "\n",
    "# Set if you want to use GPU\n",
    "# You can also use torch.cuda.is_available() to determine if cuda is available on your machine.\n",
    "cuda = False\n",
    "set_random_seeds(seed=20170629, cuda=cuda)\n",
    "\n",
    "# This will determine how many crops are processed in parallel\n",
    "input_time_length = 450\n",
    "n_classes = 2\n",
    "in_chans = train_set.X.shape[1]\n",
    "# final_conv_length determines the size of the receptive field of the ConvNet\n",
    "model = ShallowFBCSPNet(in_chans=in_chans, n_classes=n_classes, input_time_length=input_time_length,\n",
    "                        final_conv_length=12).create_network()\n",
    "to_dense_prediction_model(model)\n",
    "\n",
    "if cuda:\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "187 predictions per input/trial\n"
     ]
    }
   ],
   "source": [
    "from braindecode.torch_ext.util import np_to_var\n",
    "# determine output size\n",
    "test_input = np_to_var(np.ones((2, in_chans, input_time_length, 1), dtype=np.float32))\n",
    "if cuda:\n",
    "    test_input = test_input.cuda()\n",
    "out = model(test_input)\n",
    "n_preds_per_input = out.cpu().data.numpy().shape[2]\n",
    "print(\"{:d} predictions per input/trial\".format(n_preds_per_input))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Setup Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now we need to setup everything for the experiment: Iterator, loss function, monitors and stop criterion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from braindecode.experiments.experiment import Experiment\n",
    "from braindecode.datautil.iterators import CropsFromTrialsIterator\n",
    "from braindecode.experiments.monitors import RuntimeMonitor, LossMonitor, CroppedTrialMisclassMonitor, MisclassMonitor\n",
    "from braindecode.experiments.stopcriteria import MaxEpochs\n",
    "import torch.nn.functional as F\n",
    "import torch as th\n",
    "from braindecode.torch_ext.modules import Expression\n",
    "# Iterator is used to iterate over datasets both for training\n",
    "# and evaluation\n",
    "iterator = CropsFromTrialsIterator(batch_size=32,input_time_length=input_time_length,\n",
    "                                  n_preds_per_input=n_preds_per_input)\n",
    "\n",
    "# Loss function takes predictions as they come out of the network and the targets\n",
    "# and returns a loss\n",
    "loss_function = lambda preds, targets: F.nll_loss(th.mean(preds, dim=2)[:,:,0], targets)\n",
    "\n",
    "# Could be used to apply some constraint on the models, then should be object\n",
    "# with apply method that accepts a module\n",
    "model_constraint = None\n",
    "# Monitors log the training progress\n",
    "monitors = [LossMonitor(), MisclassMonitor(col_suffix='sample_misclass'),\n",
    "            CroppedTrialMisclassMonitor(input_time_length), RuntimeMonitor(),]\n",
    "# Stop criterion determines when the first stop happens\n",
    "stop_criterion = MaxEpochs(20)\n",
    "exp = Experiment(model, train_set, valid_set, test_set, iterator, loss_function, optimizer, model_constraint,\n",
    "          monitors, stop_criterion, remember_best_column='valid_misclass',\n",
    "          run_after_early_stop=True, batch_modifier=None, cuda=cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Run experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-07-05 13:09:17,238 INFO : Run until first stop...\n",
      "2017-07-05 13:09:17,568 INFO : Epoch 0\n",
      "2017-07-05 13:09:17,570 INFO : train_loss                0.86930\n",
      "2017-07-05 13:09:17,572 INFO : valid_loss                0.74838\n",
      "2017-07-05 13:09:17,573 INFO : test_loss                 0.69756\n",
      "2017-07-05 13:09:17,575 INFO : train_sample_misclass     0.53894\n",
      "2017-07-05 13:09:17,576 INFO : valid_sample_misclass     0.47103\n",
      "2017-07-05 13:09:17,578 INFO : test_sample_misclass      0.44251\n",
      "2017-07-05 13:09:17,579 INFO : train_misclass            0.60417\n",
      "2017-07-05 13:09:17,581 INFO : valid_misclass            0.50000\n",
      "2017-07-05 13:09:17,582 INFO : test_misclass             0.40000\n",
      "2017-07-05 13:09:17,584 INFO : runtime                   0.00000\n",
      "2017-07-05 13:09:17,585 INFO : \n",
      "2017-07-05 13:09:17,588 INFO : New best valid_misclass: 0.500000\n",
      "2017-07-05 13:09:17,589 INFO : \n",
      "2017-07-05 13:09:19,133 INFO : Epoch 1\n",
      "2017-07-05 13:09:19,136 INFO : train_loss                2.33626\n",
      "2017-07-05 13:09:19,138 INFO : valid_loss                2.31771\n",
      "2017-07-05 13:09:19,139 INFO : test_loss                 2.14077\n",
      "2017-07-05 13:09:19,141 INFO : train_sample_misclass     0.48279\n",
      "2017-07-05 13:09:19,142 INFO : valid_sample_misclass     0.50000\n",
      "2017-07-05 13:09:19,144 INFO : test_sample_misclass      0.46667\n",
      "2017-07-05 13:09:19,146 INFO : train_misclass            0.50000\n",
      "2017-07-05 13:09:19,147 INFO : valid_misclass            0.50000\n",
      "2017-07-05 13:09:19,149 INFO : test_misclass             0.46667\n",
      "2017-07-05 13:09:19,150 INFO : runtime                   1.48697\n",
      "2017-07-05 13:09:19,152 INFO : \n",
      "2017-07-05 13:09:19,154 INFO : New best valid_misclass: 0.500000\n",
      "2017-07-05 13:09:19,156 INFO : \n",
      "2017-07-05 13:09:20,640 INFO : Epoch 2\n",
      "2017-07-05 13:09:20,642 INFO : train_loss                0.59815\n",
      "2017-07-05 13:09:20,644 INFO : valid_loss                0.78503\n",
      "2017-07-05 13:09:20,645 INFO : test_loss                 0.70060\n",
      "2017-07-05 13:09:20,647 INFO : train_sample_misclass     0.33918\n",
      "2017-07-05 13:09:20,648 INFO : valid_sample_misclass     0.47995\n",
      "2017-07-05 13:09:20,650 INFO : test_sample_misclass      0.41996\n",
      "2017-07-05 13:09:20,651 INFO : train_misclass            0.22917\n",
      "2017-07-05 13:09:20,653 INFO : valid_misclass            0.41667\n",
      "2017-07-05 13:09:20,654 INFO : test_misclass             0.43333\n",
      "2017-07-05 13:09:20,656 INFO : runtime                   1.47383\n",
      "2017-07-05 13:09:20,658 INFO : \n",
      "2017-07-05 13:09:20,660 INFO : New best valid_misclass: 0.416667\n",
      "2017-07-05 13:09:20,661 INFO : \n",
      "2017-07-05 13:09:22,229 INFO : Epoch 3\n",
      "2017-07-05 13:09:22,232 INFO : train_loss                0.53121\n",
      "2017-07-05 13:09:22,233 INFO : valid_loss                0.87284\n",
      "2017-07-05 13:09:22,235 INFO : test_loss                 0.69774\n",
      "2017-07-05 13:09:22,236 INFO : train_sample_misclass     0.24588\n",
      "2017-07-05 13:09:22,238 INFO : valid_sample_misclass     0.55548\n",
      "2017-07-05 13:09:22,240 INFO : test_sample_misclass      0.42709\n",
      "2017-07-05 13:09:22,241 INFO : train_misclass            0.22917\n",
      "2017-07-05 13:09:22,243 INFO : valid_misclass            0.50000\n",
      "2017-07-05 13:09:22,244 INFO : test_misclass             0.36667\n",
      "2017-07-05 13:09:22,246 INFO : runtime                   1.59794\n",
      "2017-07-05 13:09:22,247 INFO : \n",
      "2017-07-05 13:09:23,915 INFO : Epoch 4\n",
      "2017-07-05 13:09:23,918 INFO : train_loss                0.51574\n",
      "2017-07-05 13:09:23,919 INFO : valid_loss                1.10377\n",
      "2017-07-05 13:09:23,921 INFO : test_loss                 0.80095\n",
      "2017-07-05 13:09:23,922 INFO : train_sample_misclass     0.25869\n",
      "2017-07-05 13:09:23,924 INFO : valid_sample_misclass     0.60094\n",
      "2017-07-05 13:09:23,925 INFO : test_sample_misclass      0.42727\n",
      "2017-07-05 13:09:23,927 INFO : train_misclass            0.27083\n",
      "2017-07-05 13:09:23,928 INFO : valid_misclass            0.58333\n",
      "2017-07-05 13:09:23,930 INFO : test_misclass             0.46667\n",
      "2017-07-05 13:09:23,931 INFO : runtime                   1.68490\n",
      "2017-07-05 13:09:23,933 INFO : \n",
      "2017-07-05 13:09:25,516 INFO : Epoch 5\n",
      "2017-07-05 13:09:25,522 INFO : train_loss                0.52613\n",
      "2017-07-05 13:09:25,523 INFO : valid_loss                1.22322\n",
      "2017-07-05 13:09:25,523 INFO : test_loss                 0.86285\n",
      "2017-07-05 13:09:25,524 INFO : train_sample_misclass     0.27635\n",
      "2017-07-05 13:09:25,525 INFO : valid_sample_misclass     0.58445\n",
      "2017-07-05 13:09:25,526 INFO : test_sample_misclass      0.43841\n",
      "2017-07-05 13:09:25,527 INFO : train_misclass            0.33333\n",
      "2017-07-05 13:09:25,527 INFO : valid_misclass            0.58333\n",
      "2017-07-05 13:09:25,528 INFO : test_misclass             0.46667\n",
      "2017-07-05 13:09:25,530 INFO : runtime                   1.59985\n",
      "2017-07-05 13:09:25,531 INFO : \n",
      "2017-07-05 13:09:27,121 INFO : Epoch 6\n",
      "2017-07-05 13:09:27,122 INFO : train_loss                0.54906\n",
      "2017-07-05 13:09:27,123 INFO : valid_loss                1.23573\n",
      "2017-07-05 13:09:27,124 INFO : test_loss                 0.92210\n",
      "2017-07-05 13:09:27,125 INFO : train_sample_misclass     0.28816\n",
      "2017-07-05 13:09:27,126 INFO : valid_sample_misclass     0.53810\n",
      "2017-07-05 13:09:27,126 INFO : test_sample_misclass      0.45205\n",
      "2017-07-05 13:09:27,127 INFO : train_misclass            0.33333\n",
      "2017-07-05 13:09:27,128 INFO : valid_misclass            0.58333\n",
      "2017-07-05 13:09:27,129 INFO : test_misclass             0.46667\n",
      "2017-07-05 13:09:27,131 INFO : runtime                   1.59520\n",
      "2017-07-05 13:09:27,132 INFO : \n",
      "2017-07-05 13:09:28,768 INFO : Epoch 7\n",
      "2017-07-05 13:09:28,771 INFO : train_loss                0.59627\n",
      "2017-07-05 13:09:28,772 INFO : valid_loss                1.16602\n",
      "2017-07-05 13:09:28,774 INFO : test_loss                 0.95655\n",
      "2017-07-05 13:09:28,775 INFO : train_sample_misclass     0.32253\n",
      "2017-07-05 13:09:28,777 INFO : valid_sample_misclass     0.53053\n",
      "2017-07-05 13:09:28,778 INFO : test_sample_misclass      0.46346\n",
      "2017-07-05 13:09:28,780 INFO : train_misclass            0.37500\n",
      "2017-07-05 13:09:28,782 INFO : valid_misclass            0.58333\n",
      "2017-07-05 13:09:28,783 INFO : test_misclass             0.46667\n",
      "2017-07-05 13:09:28,785 INFO : runtime                   1.64261\n",
      "2017-07-05 13:09:28,786 INFO : \n",
      "2017-07-05 13:09:30,340 INFO : Epoch 8\n",
      "2017-07-05 13:09:30,342 INFO : train_loss                0.40527\n",
      "2017-07-05 13:09:30,344 INFO : valid_loss                0.95821\n",
      "2017-07-05 13:09:30,345 INFO : test_loss                 0.79267\n",
      "2017-07-05 13:09:30,347 INFO : train_sample_misclass     0.19112\n",
      "2017-07-05 13:09:30,348 INFO : valid_sample_misclass     0.52607\n",
      "2017-07-05 13:09:30,350 INFO : test_sample_misclass      0.43351\n",
      "2017-07-05 13:09:30,351 INFO : train_misclass            0.16667\n",
      "2017-07-05 13:09:30,353 INFO : valid_misclass            0.58333\n",
      "2017-07-05 13:09:30,354 INFO : test_misclass             0.40000\n",
      "2017-07-05 13:09:30,356 INFO : runtime                   1.57786\n",
      "2017-07-05 13:09:30,357 INFO : \n",
      "2017-07-05 13:09:32,001 INFO : Epoch 9\n",
      "2017-07-05 13:09:32,005 INFO : train_loss                0.30290\n",
      "2017-07-05 13:09:32,006 INFO : valid_loss                0.89596\n",
      "2017-07-05 13:09:32,008 INFO : test_loss                 0.75205\n",
      "2017-07-05 13:09:32,009 INFO : train_sample_misclass     0.10968\n",
      "2017-07-05 13:09:32,011 INFO : valid_sample_misclass     0.56684\n",
      "2017-07-05 13:09:32,012 INFO : test_sample_misclass      0.43119\n",
      "2017-07-05 13:09:32,014 INFO : train_misclass            0.08333\n",
      "2017-07-05 13:09:32,015 INFO : valid_misclass            0.58333\n",
      "2017-07-05 13:09:32,017 INFO : test_misclass             0.36667\n",
      "2017-07-05 13:09:32,018 INFO : runtime                   1.66996\n",
      "2017-07-05 13:09:32,020 INFO : \n",
      "2017-07-05 13:09:33,502 INFO : Epoch 10\n",
      "2017-07-05 13:09:33,504 INFO : train_loss                0.25623\n",
      "2017-07-05 13:09:33,506 INFO : valid_loss                0.89555\n",
      "2017-07-05 13:09:33,508 INFO : test_loss                 0.75208\n",
      "2017-07-05 13:09:33,510 INFO : train_sample_misclass     0.06088\n",
      "2017-07-05 13:09:33,511 INFO : valid_sample_misclass     0.55637\n",
      "2017-07-05 13:09:33,513 INFO : test_sample_misclass      0.41765\n",
      "2017-07-05 13:09:33,514 INFO : train_misclass            0.02083\n",
      "2017-07-05 13:09:33,516 INFO : valid_misclass            0.58333\n",
      "2017-07-05 13:09:33,517 INFO : test_misclass             0.33333\n",
      "2017-07-05 13:09:33,519 INFO : runtime                   1.50552\n",
      "2017-07-05 13:09:33,520 INFO : \n",
      "2017-07-05 13:09:35,158 INFO : Epoch 11\n",
      "2017-07-05 13:09:35,161 INFO : train_loss                0.24021\n",
      "2017-07-05 13:09:35,163 INFO : valid_loss                0.90581\n",
      "2017-07-05 13:09:35,164 INFO : test_loss                 0.75648\n",
      "2017-07-05 13:09:35,166 INFO : train_sample_misclass     0.06205\n",
      "2017-07-05 13:09:35,167 INFO : valid_sample_misclass     0.54256\n",
      "2017-07-05 13:09:35,169 INFO : test_sample_misclass      0.39804\n",
      "2017-07-05 13:09:35,170 INFO : train_misclass            0.02083\n",
      "2017-07-05 13:09:35,171 INFO : valid_misclass            0.58333\n",
      "2017-07-05 13:09:35,173 INFO : test_misclass             0.33333\n",
      "2017-07-05 13:09:35,174 INFO : runtime                   1.64930\n",
      "2017-07-05 13:09:35,176 INFO : \n",
      "2017-07-05 13:09:36,638 INFO : Epoch 12\n",
      "2017-07-05 13:09:36,640 INFO : train_loss                0.20491\n",
      "2017-07-05 13:09:36,642 INFO : valid_loss                0.90257\n",
      "2017-07-05 13:09:36,643 INFO : test_loss                 0.75600\n",
      "2017-07-05 13:09:36,645 INFO : train_sample_misclass     0.05041\n",
      "2017-07-05 13:09:36,646 INFO : valid_sample_misclass     0.54055\n",
      "2017-07-05 13:09:36,648 INFO : test_sample_misclass      0.39501\n",
      "2017-07-05 13:09:36,650 INFO : train_misclass            0.00000\n",
      "2017-07-05 13:09:36,651 INFO : valid_misclass            0.58333\n",
      "2017-07-05 13:09:36,653 INFO : test_misclass             0.33333\n",
      "2017-07-05 13:09:36,654 INFO : runtime                   1.50060\n",
      "2017-07-05 13:09:36,656 INFO : \n",
      "2017-07-05 13:09:37,985 INFO : Epoch 13\n",
      "2017-07-05 13:09:37,988 INFO : train_loss                0.17244\n",
      "2017-07-05 13:09:37,989 INFO : valid_loss                0.90562\n",
      "2017-07-05 13:09:37,991 INFO : test_loss                 0.76539\n",
      "2017-07-05 13:09:37,992 INFO : train_sample_misclass     0.03793\n",
      "2017-07-05 13:09:37,994 INFO : valid_sample_misclass     0.56194\n",
      "2017-07-05 13:09:37,995 INFO : test_sample_misclass      0.38752\n",
      "2017-07-05 13:09:37,997 INFO : train_misclass            0.00000\n",
      "2017-07-05 13:09:37,998 INFO : valid_misclass            0.66667\n",
      "2017-07-05 13:09:38,000 INFO : test_misclass             0.36667\n",
      "2017-07-05 13:09:38,001 INFO : runtime                   1.36125\n",
      "2017-07-05 13:09:38,003 INFO : \n",
      "2017-07-05 13:09:39,333 INFO : Epoch 14\n",
      "2017-07-05 13:09:39,335 INFO : train_loss                0.15207\n",
      "2017-07-05 13:09:39,337 INFO : valid_loss                0.90600\n",
      "2017-07-05 13:09:39,338 INFO : test_loss                 0.76428\n",
      "2017-07-05 13:09:39,340 INFO : train_sample_misclass     0.02969\n",
      "2017-07-05 13:09:39,341 INFO : valid_sample_misclass     0.54924\n",
      "2017-07-05 13:09:39,343 INFO : test_sample_misclass      0.36551\n",
      "2017-07-05 13:09:39,345 INFO : train_misclass            0.00000\n",
      "2017-07-05 13:09:39,346 INFO : valid_misclass            0.58333\n",
      "2017-07-05 13:09:39,348 INFO : test_misclass             0.36667\n",
      "2017-07-05 13:09:39,349 INFO : runtime                   1.34709\n",
      "2017-07-05 13:09:39,351 INFO : \n",
      "2017-07-05 13:09:40,677 INFO : Epoch 15\n",
      "2017-07-05 13:09:40,679 INFO : train_loss                0.14998\n",
      "2017-07-05 13:09:40,681 INFO : valid_loss                0.96411\n",
      "2017-07-05 13:09:40,682 INFO : test_loss                 0.81256\n",
      "2017-07-05 13:09:40,684 INFO : train_sample_misclass     0.04027\n",
      "2017-07-05 13:09:40,685 INFO : valid_sample_misclass     0.48061\n",
      "2017-07-05 13:09:40,687 INFO : test_sample_misclass      0.35811\n",
      "2017-07-05 13:09:40,688 INFO : train_misclass            0.02083\n",
      "2017-07-05 13:09:40,690 INFO : valid_misclass            0.50000\n",
      "2017-07-05 13:09:40,691 INFO : test_misclass             0.33333\n",
      "2017-07-05 13:09:40,693 INFO : runtime                   1.34376\n",
      "2017-07-05 13:09:40,694 INFO : \n",
      "2017-07-05 13:09:42,074 INFO : Epoch 16\n",
      "2017-07-05 13:09:42,077 INFO : train_loss                0.10915\n",
      "2017-07-05 13:09:42,078 INFO : valid_loss                0.91490\n",
      "2017-07-05 13:09:42,080 INFO : test_loss                 0.80608\n",
      "2017-07-05 13:09:42,082 INFO : train_sample_misclass     0.01588\n",
      "2017-07-05 13:09:42,083 INFO : valid_sample_misclass     0.54234\n",
      "2017-07-05 13:09:42,085 INFO : test_sample_misclass      0.34537\n",
      "2017-07-05 13:09:42,086 INFO : train_misclass            0.00000\n",
      "2017-07-05 13:09:42,088 INFO : valid_misclass            0.33333\n",
      "2017-07-05 13:09:42,089 INFO : test_misclass             0.33333\n",
      "2017-07-05 13:09:42,091 INFO : runtime                   1.34378\n",
      "2017-07-05 13:09:42,092 INFO : \n",
      "2017-07-05 13:09:42,095 INFO : New best valid_misclass: 0.333333\n",
      "2017-07-05 13:09:42,097 INFO : \n",
      "2017-07-05 13:09:43,990 INFO : Epoch 17\n",
      "2017-07-05 13:09:43,992 INFO : train_loss                0.15003\n",
      "2017-07-05 13:09:43,994 INFO : valid_loss                0.91323\n",
      "2017-07-05 13:09:43,995 INFO : test_loss                 0.81002\n",
      "2017-07-05 13:09:43,997 INFO : train_sample_misclass     0.05403\n",
      "2017-07-05 13:09:43,998 INFO : valid_sample_misclass     0.51337\n",
      "2017-07-05 13:09:44,000 INFO : test_sample_misclass      0.34403\n",
      "2017-07-05 13:09:44,001 INFO : train_misclass            0.04167\n",
      "2017-07-05 13:09:44,003 INFO : valid_misclass            0.50000\n",
      "2017-07-05 13:09:44,004 INFO : test_misclass             0.23333\n",
      "2017-07-05 13:09:44,006 INFO : runtime                   1.87296\n",
      "2017-07-05 13:09:44,007 INFO : \n",
      "2017-07-05 13:09:45,338 INFO : Epoch 18\n",
      "2017-07-05 13:09:45,340 INFO : train_loss                0.09315\n",
      "2017-07-05 13:09:45,342 INFO : valid_loss                0.89064\n",
      "2017-07-05 13:09:45,344 INFO : test_loss                 0.77360\n",
      "2017-07-05 13:09:45,345 INFO : train_sample_misclass     0.01025\n",
      "2017-07-05 13:09:45,347 INFO : valid_sample_misclass     0.49666\n",
      "2017-07-05 13:09:45,348 INFO : test_sample_misclass      0.30873\n",
      "2017-07-05 13:09:45,350 INFO : train_misclass            0.00000\n",
      "2017-07-05 13:09:45,352 INFO : valid_misclass            0.33333\n",
      "2017-07-05 13:09:45,353 INFO : test_misclass             0.33333\n",
      "2017-07-05 13:09:45,355 INFO : runtime                   1.44523\n",
      "2017-07-05 13:09:45,356 INFO : \n",
      "2017-07-05 13:09:45,359 INFO : New best valid_misclass: 0.333333\n",
      "2017-07-05 13:09:45,361 INFO : \n",
      "2017-07-05 13:09:47,065 INFO : Epoch 19\n",
      "2017-07-05 13:09:47,067 INFO : train_loss                0.09407\n",
      "2017-07-05 13:09:47,068 INFO : valid_loss                0.96350\n",
      "2017-07-05 13:09:47,069 INFO : test_loss                 0.84831\n",
      "2017-07-05 13:09:47,071 INFO : train_sample_misclass     0.02078\n",
      "2017-07-05 13:09:47,072 INFO : valid_sample_misclass     0.49042\n",
      "2017-07-05 13:09:47,074 INFO : test_sample_misclass      0.33137\n",
      "2017-07-05 13:09:47,075 INFO : train_misclass            0.00000\n",
      "2017-07-05 13:09:47,077 INFO : valid_misclass            0.50000\n",
      "2017-07-05 13:09:47,079 INFO : test_misclass             0.30000\n",
      "2017-07-05 13:09:47,080 INFO : runtime                   1.55673\n",
      "2017-07-05 13:09:47,082 INFO : \n",
      "2017-07-05 13:09:48,563 INFO : Epoch 20\n",
      "2017-07-05 13:09:48,566 INFO : train_loss                0.06822\n",
      "2017-07-05 13:09:48,567 INFO : valid_loss                1.05598\n",
      "2017-07-05 13:09:48,569 INFO : test_loss                 0.88760\n",
      "2017-07-05 13:09:48,570 INFO : train_sample_misclass     0.00847\n",
      "2017-07-05 13:09:48,572 INFO : valid_sample_misclass     0.51448\n",
      "2017-07-05 13:09:48,573 INFO : test_sample_misclass      0.33066\n",
      "2017-07-05 13:09:48,575 INFO : train_misclass            0.00000\n",
      "2017-07-05 13:09:48,576 INFO : valid_misclass            0.50000\n",
      "2017-07-05 13:09:48,578 INFO : test_misclass             0.36667\n",
      "2017-07-05 13:09:48,579 INFO : runtime                   1.64454\n",
      "2017-07-05 13:09:48,581 INFO : \n",
      "2017-07-05 13:09:48,583 INFO : Setup for second stop...\n",
      "2017-07-05 13:09:48,586 INFO : Train loss to reach 0.09315\n",
      "2017-07-05 13:09:48,588 INFO : Run until second stop...\n",
      "2017-07-05 13:09:48,959 INFO : Epoch 19\n",
      "2017-07-05 13:09:48,961 INFO : train_loss                0.25265\n",
      "2017-07-05 13:09:48,963 INFO : valid_loss                0.89064\n",
      "2017-07-05 13:09:48,964 INFO : test_loss                 0.77360\n",
      "2017-07-05 13:09:48,966 INFO : train_sample_misclass     0.10753\n",
      "2017-07-05 13:09:48,967 INFO : valid_sample_misclass     0.49666\n",
      "2017-07-05 13:09:48,969 INFO : test_sample_misclass      0.30873\n",
      "2017-07-05 13:09:48,970 INFO : train_misclass            0.06667\n",
      "2017-07-05 13:09:48,972 INFO : valid_misclass            0.33333\n",
      "2017-07-05 13:09:48,973 INFO : test_misclass             0.33333\n",
      "2017-07-05 13:09:48,975 INFO : runtime                   0.45209\n",
      "2017-07-05 13:09:48,976 INFO : \n",
      "2017-07-05 13:09:50,412 INFO : Epoch 20\n",
      "2017-07-05 13:09:50,415 INFO : train_loss                0.21080\n",
      "2017-07-05 13:09:50,416 INFO : valid_loss                0.68103\n",
      "2017-07-05 13:09:50,418 INFO : test_loss                 0.73508\n",
      "2017-07-05 13:09:50,420 INFO : train_sample_misclass     0.08324\n",
      "2017-07-05 13:09:50,422 INFO : valid_sample_misclass     0.34915\n",
      "2017-07-05 13:09:50,423 INFO : test_sample_misclass      0.31025\n",
      "2017-07-05 13:09:50,425 INFO : train_misclass            0.10000\n",
      "2017-07-05 13:09:50,426 INFO : valid_misclass            0.50000\n",
      "2017-07-05 13:09:50,428 INFO : test_misclass             0.26667\n",
      "2017-07-05 13:09:50,429 INFO : runtime                   1.37581\n",
      "2017-07-05 13:09:50,431 INFO : \n",
      "2017-07-05 13:09:52,410 INFO : Epoch 21\n",
      "2017-07-05 13:09:52,412 INFO : train_loss                0.18816\n",
      "2017-07-05 13:09:52,414 INFO : valid_loss                0.46174\n",
      "2017-07-05 13:09:52,416 INFO : test_loss                 0.66965\n",
      "2017-07-05 13:09:52,417 INFO : train_sample_misclass     0.07406\n",
      "2017-07-05 13:09:52,419 INFO : valid_sample_misclass     0.24643\n",
      "2017-07-05 13:09:52,420 INFO : test_sample_misclass      0.28066\n",
      "2017-07-05 13:09:52,422 INFO : train_misclass            0.05000\n",
      "2017-07-05 13:09:52,423 INFO : valid_misclass            0.16667\n",
      "2017-07-05 13:09:52,425 INFO : test_misclass             0.26667\n",
      "2017-07-05 13:09:52,426 INFO : runtime                   1.94951\n",
      "2017-07-05 13:09:52,428 INFO : \n",
      "2017-07-05 13:09:54,146 INFO : Epoch 22\n",
      "2017-07-05 13:09:54,148 INFO : train_loss                0.13663\n",
      "2017-07-05 13:09:54,150 INFO : valid_loss                0.28806\n",
      "2017-07-05 13:09:54,151 INFO : test_loss                 0.63335\n",
      "2017-07-05 13:09:54,153 INFO : train_sample_misclass     0.02567\n",
      "2017-07-05 13:09:54,154 INFO : valid_sample_misclass     0.06796\n",
      "2017-07-05 13:09:54,156 INFO : test_sample_misclass      0.25677\n",
      "2017-07-05 13:09:54,157 INFO : train_misclass            0.00000\n",
      "2017-07-05 13:09:54,159 INFO : valid_misclass            0.00000\n",
      "2017-07-05 13:09:54,160 INFO : test_misclass             0.23333\n",
      "2017-07-05 13:09:54,162 INFO : runtime                   1.75455\n",
      "2017-07-05 13:09:54,164 INFO : \n",
      "2017-07-05 13:09:56,176 INFO : Epoch 23\n",
      "2017-07-05 13:09:56,178 INFO : train_loss                0.18469\n",
      "2017-07-05 13:09:56,180 INFO : valid_loss                0.33505\n",
      "2017-07-05 13:09:56,182 INFO : test_loss                 0.74569\n",
      "2017-07-05 13:09:56,183 INFO : train_sample_misclass     0.07469\n",
      "2017-07-05 13:09:56,185 INFO : valid_sample_misclass     0.15575\n",
      "2017-07-05 13:09:56,186 INFO : test_sample_misclass      0.29652\n",
      "2017-07-05 13:09:56,188 INFO : train_misclass            0.05000\n",
      "2017-07-05 13:09:56,189 INFO : valid_misclass            0.08333\n",
      "2017-07-05 13:09:56,191 INFO : test_misclass             0.26667\n",
      "2017-07-05 13:09:56,192 INFO : runtime                   2.01753\n",
      "2017-07-05 13:09:56,194 INFO : \n",
      "2017-07-05 13:09:58,098 INFO : Epoch 24\n",
      "2017-07-05 13:09:58,101 INFO : train_loss                0.12348\n",
      "2017-07-05 13:09:58,102 INFO : valid_loss                0.28360\n",
      "2017-07-05 13:09:58,104 INFO : test_loss                 0.78044\n",
      "2017-07-05 13:09:58,105 INFO : train_sample_misclass     0.03632\n",
      "2017-07-05 13:09:58,107 INFO : valid_sample_misclass     0.10495\n",
      "2017-07-05 13:09:58,108 INFO : test_sample_misclass      0.28529\n",
      "2017-07-05 13:09:58,110 INFO : train_misclass            0.03333\n",
      "2017-07-05 13:09:58,112 INFO : valid_misclass            0.08333\n",
      "2017-07-05 13:09:58,113 INFO : test_misclass             0.26667\n",
      "2017-07-05 13:09:58,115 INFO : runtime                   1.91925\n",
      "2017-07-05 13:09:58,116 INFO : \n",
      "2017-07-05 13:09:59,840 INFO : Epoch 25\n",
      "2017-07-05 13:09:59,842 INFO : train_loss                0.14715\n",
      "2017-07-05 13:09:59,844 INFO : valid_loss                0.19253\n",
      "2017-07-05 13:09:59,845 INFO : test_loss                 0.77622\n",
      "2017-07-05 13:09:59,847 INFO : train_sample_misclass     0.04635\n",
      "2017-07-05 13:09:59,848 INFO : valid_sample_misclass     0.05660\n",
      "2017-07-05 13:09:59,850 INFO : test_sample_misclass      0.26863\n",
      "2017-07-05 13:09:59,851 INFO : train_misclass            0.05000\n",
      "2017-07-05 13:09:59,853 INFO : valid_misclass            0.08333\n",
      "2017-07-05 13:09:59,854 INFO : test_misclass             0.23333\n",
      "2017-07-05 13:09:59,856 INFO : runtime                   1.78454\n",
      "2017-07-05 13:09:59,857 INFO : \n",
      "2017-07-05 13:10:01,991 INFO : Epoch 26\n",
      "2017-07-05 13:10:01,995 INFO : train_loss                0.33871\n",
      "2017-07-05 13:10:01,996 INFO : valid_loss                0.33738\n",
      "2017-07-05 13:10:01,998 INFO : test_loss                 0.75611\n",
      "2017-07-05 13:10:01,999 INFO : train_sample_misclass     0.16430\n",
      "2017-07-05 13:10:02,001 INFO : valid_sample_misclass     0.16689\n",
      "2017-07-05 13:10:02,002 INFO : test_sample_misclass      0.27763\n",
      "2017-07-05 13:10:02,004 INFO : train_misclass            0.11667\n",
      "2017-07-05 13:10:02,006 INFO : valid_misclass            0.16667\n",
      "2017-07-05 13:10:02,007 INFO : test_misclass             0.26667\n",
      "2017-07-05 13:10:02,009 INFO : runtime                   2.02184\n",
      "2017-07-05 13:10:02,011 INFO : \n",
      "2017-07-05 13:10:04,383 INFO : Epoch 27\n",
      "2017-07-05 13:10:04,385 INFO : train_loss                0.12510\n",
      "2017-07-05 13:10:04,385 INFO : valid_loss                0.14954\n",
      "2017-07-05 13:10:04,386 INFO : test_loss                 0.60954\n",
      "2017-07-05 13:10:04,387 INFO : train_sample_misclass     0.03111\n",
      "2017-07-05 13:10:04,387 INFO : valid_sample_misclass     0.02718\n",
      "2017-07-05 13:10:04,388 INFO : test_sample_misclass      0.23351\n",
      "2017-07-05 13:10:04,389 INFO : train_misclass            0.01667\n",
      "2017-07-05 13:10:04,390 INFO : valid_misclass            0.00000\n",
      "2017-07-05 13:10:04,390 INFO : test_misclass             0.16667\n",
      "2017-07-05 13:10:04,391 INFO : runtime                   2.44422\n",
      "2017-07-05 13:10:04,392 INFO : \n",
      "2017-07-05 13:10:06,833 INFO : Epoch 28\n",
      "2017-07-05 13:10:06,835 INFO : train_loss                0.09142\n",
      "2017-07-05 13:10:06,837 INFO : valid_loss                0.15033\n",
      "2017-07-05 13:10:06,838 INFO : test_loss                 0.64889\n",
      "2017-07-05 13:10:06,840 INFO : train_sample_misclass     0.01239\n",
      "2017-07-05 13:10:06,841 INFO : valid_sample_misclass     0.03387\n",
      "2017-07-05 13:10:06,843 INFO : test_sample_misclass      0.25856\n",
      "2017-07-05 13:10:06,844 INFO : train_misclass            0.00000\n",
      "2017-07-05 13:10:06,846 INFO : valid_misclass            0.00000\n",
      "2017-07-05 13:10:06,847 INFO : test_misclass             0.26667\n",
      "2017-07-05 13:10:06,849 INFO : runtime                   2.37887\n",
      "2017-07-05 13:10:06,850 INFO : \n",
      "2017-07-05 13:10:08,969 INFO : Epoch 29\n",
      "2017-07-05 13:10:08,971 INFO : train_loss                0.12668\n",
      "2017-07-05 13:10:08,973 INFO : valid_loss                0.21722\n",
      "2017-07-05 13:10:08,975 INFO : test_loss                 0.74796\n",
      "2017-07-05 13:10:08,976 INFO : train_sample_misclass     0.04274\n",
      "2017-07-05 13:10:08,978 INFO : valid_sample_misclass     0.08623\n",
      "2017-07-05 13:10:08,979 INFO : test_sample_misclass      0.26399\n",
      "2017-07-05 13:10:08,981 INFO : train_misclass            0.03333\n",
      "2017-07-05 13:10:08,982 INFO : valid_misclass            0.08333\n",
      "2017-07-05 13:10:08,984 INFO : test_misclass             0.23333\n",
      "2017-07-05 13:10:08,985 INFO : runtime                   2.10714\n",
      "2017-07-05 13:10:08,987 INFO : \n",
      "2017-07-05 13:10:10,983 INFO : Epoch 30\n",
      "2017-07-05 13:10:10,985 INFO : train_loss                0.07407\n",
      "2017-07-05 13:10:10,986 INFO : valid_loss                0.15270\n",
      "2017-07-05 13:10:10,988 INFO : test_loss                 0.67133\n",
      "2017-07-05 13:10:10,989 INFO : train_sample_misclass     0.01497\n",
      "2017-07-05 13:10:10,991 INFO : valid_sample_misclass     0.06061\n",
      "2017-07-05 13:10:10,992 INFO : test_sample_misclass      0.23975\n",
      "2017-07-05 13:10:10,994 INFO : train_misclass            0.01667\n",
      "2017-07-05 13:10:10,995 INFO : valid_misclass            0.08333\n",
      "2017-07-05 13:10:10,997 INFO : test_misclass             0.20000\n",
      "2017-07-05 13:10:10,998 INFO : runtime                   2.06612\n",
      "2017-07-05 13:10:11,000 INFO : \n",
      "2017-07-05 13:10:13,107 INFO : Epoch 31\n",
      "2017-07-05 13:10:13,109 INFO : train_loss                0.05036\n",
      "2017-07-05 13:10:13,111 INFO : valid_loss                0.09103\n",
      "2017-07-05 13:10:13,112 INFO : test_loss                 0.66769\n",
      "2017-07-05 13:10:13,114 INFO : train_sample_misclass     0.00744\n",
      "2017-07-05 13:10:13,115 INFO : valid_sample_misclass     0.02317\n",
      "2017-07-05 13:10:13,117 INFO : test_sample_misclass      0.20677\n",
      "2017-07-05 13:10:13,118 INFO : train_misclass            0.00000\n",
      "2017-07-05 13:10:13,120 INFO : valid_misclass            0.00000\n",
      "2017-07-05 13:10:13,121 INFO : test_misclass             0.20000\n",
      "2017-07-05 13:10:13,123 INFO : runtime                   2.15274\n",
      "2017-07-05 13:10:13,124 INFO : \n"
     ]
    }
   ],
   "source": [
    "# need to setup python logging before to be able to see anything\n",
    "import logging\n",
    "import sys\n",
    "logging.basicConfig(format='%(asctime)s %(levelname)s : %(message)s',\n",
    "                     level=logging.DEBUG, stream=sys.stdout)\n",
    "exp.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "In this case, we arrive at 80.0% accuracy, the training stops after the validation loss decreases below the training loss at the best epoch of 0.03722."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Dataset References\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    " This dataset was created and contributed to PhysioNet by the developers of the [BCI2000](http://www.schalklab.org/research/bci2000) instrumentation system, which they used in making these recordings. The system is described in:\n",
    " \n",
    "     Schalk, G., McFarland, D.J., Hinterberger, T., Birbaumer, N., Wolpaw, J.R. (2004) BCI2000: A General-Purpose Brain-Computer Interface (BCI) System. IEEE TBME 51(6):1034-1043.\n",
    "\n",
    "[PhysioBank](https://physionet.org/physiobank/) is a large and growing archive of well-characterized digital recordings of physiologic signals and related data for use by the biomedical research community and further described in:\n",
    "\n",
    "    Goldberger AL, Amaral LAN, Glass L, Hausdorff JM, Ivanov PCh, Mark RG, Mietus JE, Moody GB, Peng C-K, Stanley HE. (2000) PhysioBank, PhysioToolkit, and PhysioNet: Components of a New Research Resource for Complex Physiologic Signals. Circulation 101(23):e215-e220."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
